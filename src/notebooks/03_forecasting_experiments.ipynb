{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80980e85",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# üß™ LSTM Forecasting Model for News Engagement Prediction\n",
    "AI Course - NLP Track  \n",
    "This notebook implements the main Bidirectional LSTM model to forecast \n",
    "users' future news engagement across 7 political stances.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd426e3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63c28823",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------- Configuration & Hyperparameters --------------------\n",
    "class Config:\n",
    "    # Data\n",
    "    SEQ_LENGTH = 8          # 8 quarters = 2 years input\n",
    "    NUM_STANCES = 7         # 7 political stances (-3 to +3)\n",
    "    SAMPLE_FRACTION = 0.05  # 5% of total data for quick experimentation\n",
    "    \n",
    "    # Model Architecture\n",
    "    HIDDEN_DIM = 128\n",
    "    NUM_LAYERS = 2\n",
    "    DROPOUT = 0.3\n",
    "    BIDIRECTIONAL = True\n",
    "    \n",
    "    # Training\n",
    "    BATCH_SIZE = 32\n",
    "    LEARNING_RATE = 1e-3\n",
    "    NUM_EPOCHS = 30\n",
    "    PATIENCE = 5           # Early stopping patience\n",
    "    RANDOM_SEED = 42\n",
    "    \n",
    "    # Device\n",
    "    DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "config = Config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6617cf3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seeds for reproducibility\n",
    "random.seed(config.RANDOM_SEED)\n",
    "np.random.seed(config.RANDOM_SEED)\n",
    "torch.manual_seed(config.RANDOM_SEED)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(config.RANDOM_SEED)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "print(f\"üìå Device: {config.DEVICE}\")\n",
    "print(f\"üìå Sample fraction: {config.SAMPLE_FRACTION*100:.0f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3043dd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------- 1. Load Data with Random Sampling --------------------\n",
    "DATA_PATH = \"../data/icwsm-2024-forecasting-data-anon.json\"\n",
    "\n",
    "print(f\"üìÇ Loading {config.SAMPLE_FRACTION*100:.0f}% random sample from {DATA_PATH}...\")\n",
    "\n",
    "with open(DATA_PATH, 'r', encoding='utf-8') as f:\n",
    "    raw_data = json.load(f)\n",
    "\n",
    "print(f\"üìä Total records in full dataset: {len(raw_data):,}\")\n",
    "\n",
    "# Random sampling\n",
    "all_keys = list(raw_data.keys())\n",
    "sampled_keys = random.sample(all_keys, int(len(all_keys) * config.SAMPLE_FRACTION))\n",
    "\n",
    "records = []\n",
    "for key in tqdm(sampled_keys, desc=\"Loading records\"):\n",
    "    value = raw_data[key]\n",
    "    records.append({\n",
    "        'user_id': value['user_id_anonymized'],\n",
    "        'timestamp': pd.to_datetime(value['created_at']),\n",
    "        'stances': value['partisan stance']\n",
    "    })\n",
    "\n",
    "df = pd.DataFrame(records)\n",
    "df['quarter'] = df['timestamp'].dt.to_period('Q')\n",
    "print(f\"‚úÖ Data loaded. Total records in sample: {len(df):,}\")\n",
    "print(f\"‚úÖ Unique users: {df['user_id'].nunique():,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c861724",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------- 2. Build Time Series Sequences --------------------\n",
    "def build_sequences(df, seq_length=8):\n",
    "    \"\"\"\n",
    "    Convert user engagements into (X, y) sequences.\n",
    "    X: [n_samples, seq_length, 7] - input quarters\n",
    "    y: [n_samples, 7] - target quarter\n",
    "    \"\"\"\n",
    "    sequences = []\n",
    "    labels = []\n",
    "    users_with_sequences = 0\n",
    "    \n",
    "    for user_id, user_df in tqdm(df.groupby('user_id'), desc=\"Building sequences\"):\n",
    "        user_df = user_df.sort_values('timestamp')\n",
    "        \n",
    "        # Count engagements per quarter\n",
    "        quarterly_counts = []\n",
    "        for quarter, quarter_df in user_df.groupby('quarter'):\n",
    "            counts = np.zeros(7, dtype=np.float32)\n",
    "            for stances in quarter_df['stances']:\n",
    "                for stance in stances:\n",
    "                    idx = int(stance) + 3  # Convert -3..3 to 0..6\n",
    "                    if 0 <= idx < 7:\n",
    "                        counts[idx] += 1\n",
    "            quarterly_counts.append(counts)\n",
    "        \n",
    "        # Create sliding windows\n",
    "        if len(quarterly_counts) >= seq_length + 1:\n",
    "            users_with_sequences += 1\n",
    "            for i in range(len(quarterly_counts) - seq_length):\n",
    "                seq = quarterly_counts[i:i+seq_length]\n",
    "                label = quarterly_counts[i+seq_length]\n",
    "                sequences.append(seq)\n",
    "                labels.append(label)\n",
    "    \n",
    "    print(f\"‚úÖ Users with sequences: {users_with_sequences}\")\n",
    "    return np.array(sequences, dtype=np.float32), np.array(labels, dtype=np.float32)\n",
    "\n",
    "sequences, labels = build_sequences(df, config.SEQ_LENGTH)\n",
    "print(f\"‚úÖ Total sequences created: {len(sequences):,}\")\n",
    "print(f\"   Sequence shape: {sequences.shape}\")\n",
    "print(f\"   Label shape: {labels.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ade9e89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------- 3. Train/Validation Split --------------------\n",
    "split = int(0.8 * len(sequences))\n",
    "X_train, X_val = sequences[:split], sequences[split:]\n",
    "y_train, y_val = labels[:split], labels[split:]\n",
    "\n",
    "print(f\"\\nüìä Training set size: {len(X_train):,}\")\n",
    "print(f\"üìä Validation set size: {len(X_val):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e0f02e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------- 4. Define LSTM Model --------------------\n",
    "class NewsForecaster(nn.Module):\n",
    "    \"\"\"Bidirectional LSTM model for news engagement forecasting.\"\"\"\n",
    "    \n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        \n",
    "        # LSTM layer\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=config.NUM_STANCES,\n",
    "            hidden_size=config.HIDDEN_DIM,\n",
    "            num_layers=config.NUM_LAYERS,\n",
    "            batch_first=True,\n",
    "            dropout=config.DROPOUT if config.NUM_LAYERS > 1 else 0,\n",
    "            bidirectional=config.BIDIRECTIONAL\n",
    "        )\n",
    "        \n",
    "        # Output dimension after LSTM\n",
    "        lstm_out_dim = config.HIDDEN_DIM * (2 if config.BIDIRECTIONAL else 1)\n",
    "        \n",
    "        # Fully connected layers\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(lstm_out_dim, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(config.DROPOUT),\n",
    "            nn.Linear(64, config.NUM_STANCES)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x, return_embedding=False):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x: Input tensor [batch_size, seq_len, 7]\n",
    "            return_embedding: If True, returns hidden state for clustering\n",
    "        \n",
    "        Returns:\n",
    "            embedding: Hidden state [batch_size, hidden_dim*2]\n",
    "            output: Prediction [batch_size, 7]\n",
    "        \"\"\"\n",
    "        _, (h_n, _) = self.lstm(x)\n",
    "        \n",
    "        # Extract last hidden states from both directions\n",
    "        if self.lstm.bidirectional:\n",
    "            h_forward = h_n[-2, :, :]\n",
    "            h_backward = h_n[-1, :, :]\n",
    "            embedding = torch.cat([h_forward, h_backward], dim=1)\n",
    "        else:\n",
    "            embedding = h_n[-1, :, :]\n",
    "        \n",
    "        output = self.fc(embedding)\n",
    "        \n",
    "        if return_embedding:\n",
    "            return embedding, output\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22aecd36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------- 5. Training Function --------------------\n",
    "def train_model(config, X_train, y_train, X_val, y_val):\n",
    "    \"\"\"Train the LSTM model with early stopping.\"\"\"\n",
    "    \n",
    "    # Convert to tensors\n",
    "    train_dataset = TensorDataset(torch.FloatTensor(X_train), torch.FloatTensor(y_train))\n",
    "    val_dataset = TensorDataset(torch.FloatTensor(X_val), torch.FloatTensor(y_val))\n",
    "    \n",
    "    train_loader = DataLoader(train_dataset, batch_size=config.BATCH_SIZE, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=config.BATCH_SIZE, shuffle=False)\n",
    "    \n",
    "    # Initialize model\n",
    "    model = NewsForecaster(config).to(config.DEVICE)\n",
    "    criterion = nn.L1Loss()  # MAE loss\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=config.LEARNING_RATE)\n",
    "    \n",
    "    train_losses, val_losses = [], []\n",
    "    best_val_loss = float('inf')\n",
    "    patience_counter = 0\n",
    "    \n",
    "    for epoch in range(config.NUM_EPOCHS):\n",
    "        # Training phase\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        for batch_X, batch_y in train_loader:\n",
    "            batch_X, batch_y = batch_X.to(config.DEVICE), batch_y.to(config.DEVICE)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            pred = model(batch_X)\n",
    "            loss = criterion(pred, batch_y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            train_loss += loss.item()\n",
    "        train_loss /= len(train_loader)\n",
    "        train_losses.append(train_loss)\n",
    "        \n",
    "        # Validation phase\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for batch_X, batch_y in val_loader:\n",
    "                batch_X, batch_y = batch_X.to(config.DEVICE), batch_y.to(config.DEVICE)\n",
    "                pred = model(batch_X)\n",
    "                loss = criterion(pred, batch_y)\n",
    "                val_loss += loss.item()\n",
    "        val_loss /= len(val_loader)\n",
    "        val_losses.append(val_loss)\n",
    "        \n",
    "        print(f\"Epoch {epoch+1:2d}/{config.NUM_EPOCHS} | \"\n",
    "              f\"Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f}\")\n",
    "        \n",
    "        # Early stopping\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            patience_counter = 0\n",
    "            torch.save(model.state_dict(), \"best_model.pt\")\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            if patience_counter >= config.PATIENCE:\n",
    "                print(f\"‚ö†Ô∏è Early stopping triggered at epoch {epoch+1}\")\n",
    "                break\n",
    "    \n",
    "    # Load best model\n",
    "    model.load_state_dict(torch.load(\"best_model.pt\"))\n",
    "    return model, train_losses, val_losses\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc5d54a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------- 6. Train Model --------------------\n",
    "print(\"\\nüöÄ Starting LSTM model training...\")\n",
    "model, train_losses, val_losses = train_model(config, X_train, y_train, X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a771970d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------- 7. Learning Curves --------------------\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.plot(train_losses, label='Train Loss', linewidth=2)\n",
    "plt.plot(val_losses, label='Validation Loss', linewidth=2)\n",
    "plt.xlabel('Epoch', fontsize=12)\n",
    "plt.ylabel('MAE Loss', fontsize=12)\n",
    "plt.title('üìâ Learning Curves - LSTM Forecaster', fontsize=16)\n",
    "plt.legend(fontsize=12)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d04c546a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------- 8. Evaluation --------------------\n",
    "model.eval()\n",
    "val_dataset = TensorDataset(torch.FloatTensor(X_val), torch.FloatTensor(y_val))\n",
    "val_loader = DataLoader(val_dataset, batch_size=config.BATCH_SIZE, shuffle=False)\n",
    "\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "with torch.no_grad():\n",
    "    for batch_X, batch_y in val_loader:\n",
    "        batch_X = batch_X.to(config.DEVICE)\n",
    "        pred = model(batch_X).cpu().numpy()\n",
    "        all_preds.append(pred)\n",
    "        all_labels.append(batch_y.numpy())\n",
    "\n",
    "all_preds = np.vstack(all_preds)\n",
    "all_labels = np.vstack(all_labels)\n",
    "\n",
    "# Calculate MAE per stance\n",
    "mae_per_stance = np.mean(np.abs(all_preds - all_labels), axis=0)\n",
    "avg_mae = np.mean(mae_per_stance)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üìä MODEL EVALUATION ON VALIDATION SET\")\n",
    "print(\"=\"*60)\n",
    "stances = [-3, -2, -1, 0, 1, 2, 3]\n",
    "for i, stance in enumerate(stances):\n",
    "    print(f\"  Stance {stance:2d}: MAE = {mae_per_stance[i]:.4f}\")\n",
    "print(f\"\\n‚úÖ Average MAE: {avg_mae:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21dc1350",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------- 9. Baseline Comparison (Last Value) --------------------\n",
    "baseline_preds = X_val[:, -1, :]  # Last observed quarter\n",
    "baseline_mae = np.mean(np.abs(baseline_preds - y_val), axis=0)\n",
    "baseline_avg_mae = np.mean(baseline_mae)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üìä BASELINE COMPARISON (Last Value)\")\n",
    "print(\"=\"*60)\n",
    "for i, stance in enumerate(stances):\n",
    "    improvement = (baseline_mae[i] - mae_per_stance[i]) / baseline_mae[i] * 100\n",
    "    print(f\"  Stance {stance:2d}: Baseline MAE = {baseline_mae[i]:.4f} | \"\n",
    "          f\"LSTM MAE = {mae_per_stance[i]:.4f} | \"\n",
    "          f\"Improvement = {improvement:.1f}%\")\n",
    "\n",
    "print(f\"\\n‚úÖ Baseline Average MAE: {baseline_avg_mae:.4f}\")\n",
    "print(f\"‚úÖ LSTM Average MAE: {avg_mae:.4f}\")\n",
    "print(f\"üìà Overall Improvement: {(baseline_avg_mae - avg_mae) / baseline_avg_mae * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7afc6882",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------- 10. Scatter Plot: True vs Predicted --------------------\n",
    "fig, axes = plt.subplots(2, 4, figsize=(16, 8))\n",
    "axes = axes.ravel()\n",
    "\n",
    "for i, stance in enumerate(stances):\n",
    "    ax = axes[i]\n",
    "    ax.scatter(all_labels[:, i], all_preds[:, i], alpha=0.5, s=10, color='purple')\n",
    "    \n",
    "    # Identity line\n",
    "    max_val = max(np.max(all_labels[:, i]), np.max(all_preds[:, i]))\n",
    "    ax.plot([0, max_val], [0, max_val], 'r--', linewidth=1, label='Perfect Prediction')\n",
    "    \n",
    "    ax.set_xlabel('True Values', fontsize=10)\n",
    "    ax.set_ylabel('Predicted Values', fontsize=10)\n",
    "    ax.set_title(f'Stance {stance}', fontsize=12)\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    ax.legend(fontsize=8)\n",
    "\n",
    "axes[-1].axis('off')\n",
    "plt.suptitle('üéØ True vs Predicted Engagement Counts', fontsize=16)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f19b290e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------- 11. Error Distribution --------------------\n",
    "errors = all_preds - all_labels\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.hist(errors.flatten(), bins=50, color='steelblue', edgecolor='black', alpha=0.7)\n",
    "plt.xlabel('Prediction Error', fontsize=12)\n",
    "plt.ylabel('Frequency', fontsize=12)\n",
    "plt.title('üìä Distribution of Prediction Errors', fontsize=16)\n",
    "plt.axvline(0, color='red', linestyle='--', linewidth=2)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nüìä Error Statistics:\")\n",
    "print(f\"   Mean Error: {np.mean(errors):.4f}\")\n",
    "print(f\"   Std Error: {np.std(errors):.4f}\")\n",
    "print(f\"   95% CI: [{np.percentile(errors, 2.5):.4f}, {np.percentile(errors, 97.5):.4f}]\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f21847ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------- 12. Save Model --------------------\n",
    "import os\n",
    "os.makedirs('../models_saved', exist_ok=True)\n",
    "torch.save(model.state_dict(), '../models_saved/lstm_forecaster.pt')\n",
    "print(\"\\nüíæ Model saved to ../models_saved/lstm_forecaster.pt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e2c2725",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n‚úÖ LSTM forecasting experiments completed successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b140fbd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b0b3379",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
