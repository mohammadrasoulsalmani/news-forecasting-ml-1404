#!/usr/bin/env python
# -*- coding: utf-8 -*-

"""
Training Pipeline for Political News Engagement Forecasting.
Complete pipeline with detailed progress tracking.
"""

import sys
import time
from pathlib import Path

# Add project root to Python path
sys.path.append(str(Path(__file__).parent.parent))

import torch
import pickle
import numpy as np
from torch.utils.data import DataLoader, TensorDataset

from config.settings import Config
from dataLoader.loader import DataLoader as NewsDataLoader
from dataLoader.preprocessor import SequenceBuilder
from models.forecaster import NewsForecaster
from training.trainer import Trainer
from evaluation.clustering import ClusterAnalyzer
from visualization.plots import Visualizer
from utils.helpers import set_seed


def print_section(title):
    """Print formatted section header."""
    print("\n" + "="*60)
    print(f"üìå {title}")
    print("="*60)


def main():
    """Execute the complete training and analysis pipeline."""
    
    # Initialize configuration and set random seed
    config = Config()
    set_seed(config.RANDOM_SEED)
    
    print("="*60)
    print("üì∞ POLITICAL NEWS ENGAGEMENT FORECASTING")
    print("="*60)
    print(f"üìä Configuration:")
    print(f"   ‚Ä¢ Device: {config.DEVICE}")
    print(f"   ‚Ä¢ Sample fraction: {config.SAMPLE_FRACTION:.0%}")
    print(f"   ‚Ä¢ Sequence length: {config.SEQ_LENGTH}")
    print(f"   ‚Ä¢ Hidden dim: {config.HIDDEN_DIM}")
    print(f"   ‚Ä¢ Batch size: {config.BATCH_SIZE}")
    print("="*60)
    
    # ---------- 1. Data Loading ----------
    print_section("DATA LOADING")
    start_time = time.time()
    
    loader = NewsDataLoader(config)
    df = loader.load(sample_fraction=config.SAMPLE_FRACTION)
    
    load_time = time.time() - start_time
    print(f"‚è±Ô∏è  Data loading completed in {load_time:.1f} seconds")
    
    # ---------- 2. Sequence Building ----------
    print_section("SEQUENCE BUILDING")
    start_time = time.time()
    
    builder = SequenceBuilder(config)
    sequences, labels = builder.build(df)
    
    build_time = time.time() - start_time
    print(f"‚è±Ô∏è  Sequence building completed in {build_time:.1f} seconds")
    print(f"üìä Final dataset: {len(sequences):,} sequences, shape {sequences.shape}")
    
    # ---------- 3. Train/Validation Split ----------
    print_section("DATA SPLIT")
    split = int(len(sequences) * (1 - config.TEST_SPLIT))
    X_train, X_val = sequences[:split], sequences[split:]
    y_train, y_val = labels[:split], labels[split:]
    
    train_dataset = TensorDataset(torch.FloatTensor(X_train), torch.FloatTensor(y_train))
    val_dataset = TensorDataset(torch.FloatTensor(X_val), torch.FloatTensor(y_val))
    
    train_loader = DataLoader(train_dataset, batch_size=config.BATCH_SIZE, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=config.BATCH_SIZE, shuffle=False)
    
    print(f"   ‚úÖ Training set: {len(X_train):,} sequences ({len(X_train)/len(sequences):.1%})")
    print(f"   ‚úÖ Validation set: {len(X_val):,} sequences ({len(X_val)/len(sequences):.1%})")
    print(f"   üì¶ Training batches: {len(train_loader)}")
    print(f"   üì¶ Validation batches: {len(val_loader)}")
    
    # ---------- 4. Model Training ----------
    print_section("MODEL TRAINING")
    
    model = NewsForecaster(config)
    print(f"   üß† Model architecture:")
    print(f"      ‚Ä¢ LSTM: {config.NUM_LAYERS} layers, {config.HIDDEN_DIM} units")
    print(f"      ‚Ä¢ Bidirectional: {config.BIDIRECTIONAL}")
    print(f"      ‚Ä¢ Dropout: {config.DROPOUT}")
    print(f"      ‚Ä¢ Output: {config.NUM_STANCES} stances")
    
    trainer = Trainer(config, model, train_loader, val_loader)
    train_losses, val_losses, val_preds, val_labels = trainer.fit()
    
    # ---------- 5. Model Saving ----------
    print_section("MODEL SAVING")
    model_path = config.MODEL_SAVE_DIR / "full_model.pth"
    torch.save(model.state_dict(), model_path)
    print(f"   üíæ Model saved to {model_path}")
    print(f"   üì¶ Model size: {Path(model_path).stat().st_size / 1024 / 1024:.1f} MB")
    
    # ---------- 6. User Clustering ----------
    print_section("USER CLUSTERING")
    
    analyzer = ClusterAnalyzer(config)
    
    # Step 6.1: Extract hidden states
    print("   üì• Step 1/3: Extracting hidden states from LSTM...")
    start_time = time.time()
    hidden = analyzer.extract_hidden_states(model, val_loader)
    extract_time = time.time() - start_time
    print(f"      ‚úÖ Extracted {len(hidden):,} embeddings with shape {hidden.shape}")
    print(f"      ‚è±Ô∏è  Time: {extract_time:.1f} seconds")
    
    # Step 6.2: K-means clustering
    print(f"\n   üîç Step 2/3: Running K-means with {config.NUM_CLUSTERS} clusters...")
    start_time = time.time()
    cluster_labels = analyzer.cluster_users(hidden)
    cluster_time = time.time() - start_time
    print(f"      ‚úÖ Clustering completed")
    print(f"      ‚è±Ô∏è  Time: {cluster_time:.1f} seconds")
    
    # Analyze cluster distribution
    unique, counts = np.unique(cluster_labels, return_counts=True)
    print(f"      üìä Cluster size distribution:")
    for cid, count in sorted(zip(unique, counts), key=lambda x: x[1], reverse=True)[:5]:
        print(f"         ‚Ä¢ Cluster {cid}: {count:,} users ({count/len(cluster_labels):.1%})")
    
    # Step 6.3: Analyze cluster engagements
    print(f"\n   üìä Step 3/3: Analyzing cluster engagement patterns...")
    start_time = time.time()
    cluster_data = analyzer.analyze_cluster_engagements(cluster_labels, val_labels)
    analyze_time = time.time() - start_time
    print(f"      ‚úÖ Analyzed {len(cluster_data)} clusters")
    print(f"      ‚è±Ô∏è  Time: {analyze_time:.1f} seconds")
    
    # Show cluster stances
    print(f"\n   üìà Cluster political stances:")
    sorted_clusters = sorted(cluster_data.items(), key=lambda x: x[1]['avg_stance'])
    for cid, data in sorted_clusters[:3]:
        stance_desc = "Liberal" if data['avg_stance'] < -0.5 else "Centrist" if abs(data['avg_stance']) < 0.5 else "Conservative"
        print(f"      ‚Ä¢ Cluster {cid}: {data['size']} users, avg stance: {data['avg_stance']:.2f} ({stance_desc})")
    print("      ‚Ä¢ ...")
    for cid, data in sorted_clusters[-3:]:
        stance_desc = "Liberal" if data['avg_stance'] < -0.5 else "Centrist" if abs(data['avg_stance']) < 0.5 else "Conservative"
        print(f"      ‚Ä¢ Cluster {cid}: {data['size']} users, avg stance: {data['avg_stance']:.2f} ({stance_desc})")
    
    total_cluster_time = extract_time + cluster_time + analyze_time
    print(f"\n   ‚è±Ô∏è  Total clustering time: {total_cluster_time:.1f} seconds")
    
    # ---------- 7. Visualization ----------
    print_section("VISUALIZATION")
    
    viz = Visualizer(config)
    
    print("   üé® Plot 1/2: Training curves...")
    viz.plot_training_curves(train_losses, val_losses)
    
    print("   üé® Plot 2/2: Cluster heatmap...")
    viz.plot_cluster_heatmap(cluster_data)
    
    # ---------- 8. Save Results ----------
    print_section("SAVING RESULTS")
    
    results_path = config.RESULT_DIR / "cluster_results.pkl"
    with open(results_path, "wb") as f:
        pickle.dump({
            'cluster_data': cluster_data,
            'cluster_labels': cluster_labels,
            'hidden_states': hidden,
            'train_losses': train_losses,
            'val_losses': val_losses,
            'val_predictions': val_preds,
            'val_labels': val_labels,
            'config': {k: v for k, v in config.__dict__.items() if not k.startswith('_')}
        }, f)
    
    print(f"   üíæ Results saved to {results_path}")
    print(f"   üì¶ File size: {results_path.stat().st_size / 1024:.1f} KB")
    
    # ---------- 9. Summary ----------
    print_section("PIPELINE COMPLETED")
    print(f"   ‚úÖ Status: SUCCESS")
    print(f"   üìÅ Output directory: {config.RESULT_DIR}")
    print(f"   ‚Ä¢ Model: {model_path.name}")
    print(f"   ‚Ä¢ Results: {results_path.name}")
    print(f"   ‚Ä¢ Figures: {config.FIGURE_DIR}")
    print(f"\n   üìä Final statistics:")
    print(f"      ‚Ä¢ Users analyzed: {df['user_id'].nunique():,}")
    print(f"      ‚Ä¢ Sequences created: {len(sequences):,}")
    print(f"      ‚Ä¢ Clusters discovered: {len(cluster_data)}")
    print(f"      ‚Ä¢ Model MAE: {np.mean(np.abs(val_preds - val_labels)):.4f}")
    
    print("\n" + "="*60)
    print("üéØ PIPELINE EXECUTION COMPLETE")
    print("="*60)


if __name__ == "__main__":
    main()